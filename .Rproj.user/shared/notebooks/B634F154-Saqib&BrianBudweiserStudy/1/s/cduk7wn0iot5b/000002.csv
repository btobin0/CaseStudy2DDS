"0","q9_v2 = "
"0","  q9 %>%"
"0","  select(beer_type, ABV, IBU, Region) %>%"
"0","  na.omit()"
"0","#Select train and test datasets "
"0","r = nrow(q9_v2)"
"0","p = 0.8 "
"0","n = as.integer(p*r)"
"0","iterations = 100"
"0","accuracies = numeric(iterations)"
"0","set.seed(189)"
"0","myseeds = runif(iterations) %>% multiply_by(1000) %>% round()"
"0","for(i in 1:iterations)"
"0","{"
"0","  set.seed(myseeds[i])"
"0","  index = sample(1:r, n, replace = F)"
"0","  test.data = q9_v2[index,] "
"0","  train.data = q9_v2[-index,]"
"0","    glm("
"0","      formula = beer_type ~ ABV + IBU + Region, "
"0","      data = q9_v2, "
"0","      family = binomial(""logit"") # logit, probit, cauchit"
"0","      ) -> glm_v0"
"0","    predicted = "
"0","      predict.glm(glm_v0, newdata = test.data, type = ""response"") %>%"
"0","      as.numeric() %>%"
"0","      is_weakly_greater_than(0.5) %>%"
"0","      ifelse(""IPAs"", ""Ale"") %>%"
"0","      as.factor()"
"0","    confMat = confusionMatrix(table(predicted, test.data$beer_type))"
"0","    accuracies[i] = confMat$overall[1]"
"0","}"
"0","avg_acc = mean(accuracies)"
